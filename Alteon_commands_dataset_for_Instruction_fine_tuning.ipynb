{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "from datasets import concatenate_datasets\n",
        "import pandas as pd\n",
        "import pickle"
      ],
      "metadata": {
        "id": "1fH4VFi2Si0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating dataset of alteon commands to intruction fine tune llama 2-7b-chat model**\n",
        "\n",
        "- applying specific formatting and chat prompt to my alteon commands dataset including the INST and <<SYS>> tags, BOS and EOS tokens that were used to train this chat version of llama2"
      ],
      "metadata": {
        "id": "x3Oay2GRTB9Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1Ub1RLkN8lv"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('instructionsetalteon_virt.pkl', 'rb') as f:\n",
        "    mastervirt = pickle.load(f)\n",
        "\n",
        "with open('instructionsetalteon_real.pkl', 'rb') as f:\n",
        "    masterreal = pickle.load(f)\n",
        "\n",
        "with open('instructionsetalteon_grp.pkl', 'rb') as f:\n",
        "    mastergrp = pickle.load(f)\n",
        "\n",
        "\n",
        "\n",
        "datasetvirt = Dataset.from_dict(mastervirt)\n",
        "datasetvirt = datasetvirt.shuffle(seed=42)\n",
        "\n",
        "\n",
        "datasetreal = Dataset.from_dict(masterreal)\n",
        "datasetreal = datasetreal.shuffle(seed=42)\n",
        "\n",
        "\n",
        "datasetgrp = Dataset.from_dict(mastergrp)\n",
        "datasetgrp = datasetgrp.shuffle(seed=42)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "syspromptvirt=\"\"\"You are a helpful chat assistant that only responds with alteon commands. Below is an instruction that describes an alteon virtual server related task. First extract the IP address from the instruction text and then use it when writing a response that provides alteon commands for the instruction.\"\"\"\n",
        "\n",
        "syspromptreal=\"\"\"You are a helpful chat assistant that only responds with alteon commands. Below is an instruction that describes an alteon real server related task. First extract the IP address from the instruction text and then use it when writing a response that provides alteon commands for the instruction.\"\"\"\n",
        "\n",
        "syspromptgroup=\"\"\"You are a helpful chat assistant that only responds with alteon commands. Below is an instruction that describes an alteon group related task. Write a response that provides alteon commands for it.\"\"\"\n",
        "\n",
        "formatted_prompt = []\n",
        "\n",
        "def prompt_template_virt(examples):\n",
        "    for c,i in enumerate(examples[\"query\"]):\n",
        "        if i.endswith(\"\\n\"):\n",
        "            i=i[:-1]\n",
        "        i = \"### Instruction: \"+i\n",
        "        resp = \"### Response: \"+ examples[\"response\"][c]\n",
        "        formatted_prompt.append(f'<s>[INST] <<SYS>>\\n{syspromptvirt}\\n<</SYS>>\\n\\n{i} [/INST] {resp} </s>')\n",
        "    return {\"prompt\":formatted_prompt}\n",
        "\n",
        "prompt_dataset_virt = datasetvirt.map(prompt_template_virt, batched=True)\n",
        "\n",
        "formatted_prompt = []\n",
        "\n",
        "def prompt_template_virt(examples):\n",
        "    for c,i in enumerate(examples[\"query\"]):\n",
        "        if i.endswith(\"\\n\"):\n",
        "            i=i[:-1]\n",
        "        i = \"### Instruction: \"+i\n",
        "        resp = \"### Response: \"+ examples[\"response\"][c]\n",
        "        formatted_prompt.append(f'<s>[INST] <<SYS>>\\n{syspromptvirt}\\n<</SYS>>\\n\\n{i} [/INST] {resp} </s>')\n",
        "    return {\"prompt\":formatted_prompt}\n",
        "\n",
        "prompt_dataset_virtip = datasetvirtip.map(prompt_template_virt, batched=True)\n",
        "\n",
        "formatted_prompt = []\n",
        "\n",
        "def prompt_template_virt(examples):\n",
        "    for c,i in enumerate(examples[\"query\"]):\n",
        "        if i.endswith(\"\\n\"):\n",
        "            i=i[:-1]\n",
        "        i = \"### Instruction: \"+i\n",
        "        resp = \"### Response: \"+ examples[\"response\"][c]\n",
        "        formatted_prompt.append(f'<s>[INST] <<SYS>>\\n{syspromptvirt}\\n<</SYS>>\\n\\n{i} [/INST] {resp} </s>')\n",
        "    return {\"prompt\":formatted_prompt}\n",
        "\n",
        "prompt_dataset_virtgrp = datasetvirtgrp.map(prompt_template_virt, batched=True)\n",
        "\n",
        "\n",
        "formatted_prompt = []\n",
        "\n",
        "def prompt_template_real(examples):\n",
        "    for c,i in enumerate(examples[\"query\"]):\n",
        "        if i.endswith(\"\\n\"):\n",
        "            i=i[:-1]\n",
        "        i = \"### Instruction: \"+i\n",
        "        resp = \"### Response: \"+ examples[\"response\"][c]\n",
        "        formatted_prompt.append(f'<s>[INST] <<SYS>>\\n{syspromptreal}\\n<</SYS>>\\n\\n{i} [/INST] {resp} </s>')\n",
        "    return {\"prompt\":formatted_prompt}\n",
        "\n",
        "prompt_dataset_real = datasetreal.map(prompt_template_real, batched=True)\n",
        "\n",
        "formatted_prompt = []\n",
        "\n",
        "def prompt_template_grp(examples):\n",
        "    for c,i in enumerate(examples[\"query\"]):\n",
        "        if i.endswith(\"\\n\"):\n",
        "            i=i[:-1]\n",
        "        i = \"### Instruction: \"+i\n",
        "        resp = \"### Response: \"+ examples[\"response\"][c]\n",
        "        formatted_prompt.append(f'<s>[INST] <<SYS>>\\n{syspromptgroup}\\n<</SYS>>\\n\\n{i} [/INST] {resp} </s>')\n",
        "    return {\"prompt\":formatted_prompt}\n",
        "\n",
        "prompt_dataset_grp = datasetgrp.map(prompt_template_grp, batched=True)\n"
      ],
      "metadata": {
        "id": "jPZcfRWKSKvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# concatanate all ds and shuffle them up\n",
        "\n",
        "\n",
        "master_prompt_ds = concatenate_datasets([prompt_dataset_virt, prompt_dataset_real, prompt_dataset_grp, prompt_dataset_virtip,\n",
        "                                        prompt_dataset_virtgrp])\n",
        "print (master_prompt_ds)\n",
        "\n",
        "master_prompt_ds = master_prompt_ds.shuffle(seed=42)"
      ],
      "metadata": {
        "id": "jjE6jAnhSOJn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}